{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xwi3SQQU2Wm",
        "outputId": "2990818b-a438-46fa-a617-3f24e8da60a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Define dataset paths\n",
        "ORIGINAL_TRAIN_PATH = \"/content/drive/MyDrive/Cavity Dataset/train/\"\n",
        "ORIGINAL_TEST_PATH = \"/content/drive/MyDrive/Cavity Dataset/test/\"\n",
        "COPIED_TRAIN_PATH = \"dataset_cv/train/\"\n",
        "COPIED_TEST_PATH = \"dataset_cv/test/\"\n",
        "\n",
        "# Function to check if an image is valid (not corrupted)\n",
        "def is_valid_image(img_path):\n",
        "    try:\n",
        "        img = cv2.imread(img_path)\n",
        "        return img is not None\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Function to copy dataset while removing corrupted images\n",
        "def copy_dataset(src, dest):\n",
        "    if os.path.exists(dest):\n",
        "        shutil.rmtree(dest)  # Remove existing copy\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    for class_folder in os.listdir(src):\n",
        "        src_class_path = os.path.join(src, class_folder)\n",
        "        dest_class_path = os.path.join(dest, class_folder)\n",
        "        os.makedirs(dest_class_path, exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(src_class_path):\n",
        "            img_path = os.path.join(src_class_path, filename)\n",
        "            if is_valid_image(img_path):\n",
        "                shutil.copy(img_path, dest_class_path)\n",
        "\n",
        "# Create a copy of the dataset, removing corrupted images\n",
        "copy_dataset(ORIGINAL_TRAIN_PATH, COPIED_TRAIN_PATH)\n",
        "copy_dataset(ORIGINAL_TEST_PATH, COPIED_TEST_PATH)\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load copied dataset\n",
        "train_dataset = ImageFolder(root=COPIED_TRAIN_PATH, transform=transform)\n",
        "\n",
        "# Extract features for SMOTE\n",
        "def extract_features(dataset):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image, label in dataset:\n",
        "        data.append(image.view(-1).numpy())  # Flatten the image\n",
        "        labels.append(label)\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Apply SMOTE\n",
        "def apply_smote(dataset):\n",
        "    data, labels = extract_features(dataset)\n",
        "    smote = SMOTE(random_state=SEED)\n",
        "    data_resampled, labels_resampled = smote.fit_resample(data, labels)\n",
        "    print(f\"SMOTE applied: Original count {len(labels)}, Resampled count {len(labels_resampled)}\")\n",
        "\n",
        "apply_smote(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqRv3K2QU37t",
        "outputId": "57091725-e921-42f2-f98a-ea01f248461a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE applied: Original count 707, Resampled count 776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load Pre-trained Models with Correct Weights\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Remove final classification layers\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])  # ResNet outputs (batch, 512, 1, 1)\n",
        "inception.fc = nn.Identity()  # Remove Inception's classification layer\n",
        "\n",
        "# Move models to device\n",
        "resnet18.to(device).eval()\n",
        "inception.to(device).eval()\n",
        "\n",
        "# Define Image Transformations (InceptionNet requires 299x299 input size)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load Training and Test Data\n",
        "train_dataset = datasets.ImageFolder(root=\"dataset_cv/train/\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=\"dataset_cv/test/\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Function to extract features from both models\n",
        "def extract_features(loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(loader, desc=\"Extracting Features\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Extract features\n",
        "            resnet_features = resnet18(images).squeeze(-1).squeeze(-1)  # Shape: (batch, 512)\n",
        "            inception_features = inception(images)  # Shape: (batch, 2048)\n",
        "\n",
        "            # Flatten and concatenate features\n",
        "            resnet_features = resnet_features.cpu().numpy()\n",
        "            inception_features = inception_features.cpu().numpy()\n",
        "\n",
        "            combined_features = np.hstack((resnet_features, inception_features))\n",
        "\n",
        "            # Store features and labels\n",
        "            features.extend(combined_features)\n",
        "            labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Extract features for training and testing\n",
        "X_train, y_train = extract_features(train_loader)\n",
        "X_test, y_test = extract_features(test_loader)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Generate Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=train_dataset.classes)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52afQKR5W_fV",
        "outputId": "c62f28c6-0b3f-4958-9d85-7ca54fe86bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 100MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:01<00:00, 87.2MB/s]\n",
            "Extracting Features: 100%|██████████| 23/23 [07:24<00:00, 19.34s/it]\n",
            "Extracting Features:  83%|████████▎ | 5/6 [01:40<00:19, 19.98s/it]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
            "  warnings.warn(str(msg))\n",
            "Extracting Features: 100%|██████████| 6/6 [01:51<00:00, 18.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      cavity       0.82      0.92      0.87        97\n",
            "   no_cavity       0.88      0.76      0.82        79\n",
            "\n",
            "    accuracy                           0.85       176\n",
            "   macro avg       0.85      0.84      0.84       176\n",
            "weighted avg       0.85      0.85      0.84       176\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rluuW1XH1B1T",
        "outputId": "3aacfd9b-9fd1-4f7e-8b2f-9e962a57f4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Define dataset paths\n",
        "ORIGINAL_TRAIN_PATH = \"/content/drive/MyDrive/Cavity Dataset/train/\"\n",
        "ORIGINAL_TEST_PATH = \"/content/drive/MyDrive/Cavity Dataset/test/\"\n",
        "COPIED_TRAIN_PATH = \"dataset_cro/train/\"\n",
        "COPIED_TEST_PATH = \"dataset_cro/test/\"\n",
        "TARGET_COUNT = 788  # Target number of images per class\n",
        "\n",
        "# Function to check if an image is valid (not corrupted)\n",
        "def is_valid_image(img_path):\n",
        "    try:\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            return False\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Function to copy dataset while removing corrupted images\n",
        "def copy_dataset(src, dest):\n",
        "    if os.path.exists(dest):\n",
        "        shutil.rmtree(dest)  # Remove existing copy\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    for class_folder in os.listdir(src):\n",
        "        src_class_path = os.path.join(src, class_folder)\n",
        "        dest_class_path = os.path.join(dest, class_folder)\n",
        "        os.makedirs(dest_class_path, exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(src_class_path):\n",
        "            img_path = os.path.join(src_class_path, filename)\n",
        "            if is_valid_image(img_path):  # Check if image is valid\n",
        "                shutil.copy(img_path, dest_class_path)  # Copy only valid images\n",
        "\n",
        "# Create a copy of the dataset, removing corrupted images\n",
        "copy_dataset(ORIGINAL_TRAIN_PATH, COPIED_TRAIN_PATH)\n",
        "copy_dataset(ORIGINAL_TEST_PATH, COPIED_TEST_PATH)\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load copied dataset\n",
        "train_dataset = ImageFolder(root=COPIED_TRAIN_PATH, transform=transform)\n",
        "\n",
        "# Load pre-trained ResNet50 as feature extractor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(dataset, indices):\n",
        "    dataloader = DataLoader(Subset(dataset, indices), batch_size=32, shuffle=False)\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in tqdm(dataloader, desc=\"Extracting Features\"):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            features.extend(outputs.squeeze().cpu().numpy())\n",
        "    return np.array(features)\n",
        "\n",
        "# Perform Adaptive Sampling via Clustering for both classes\n",
        "def adaptive_oversampling(class_name):\n",
        "    class_path = os.path.join(COPIED_TRAIN_PATH, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "    image_paths = [os.path.join(class_path, img) for img in images]\n",
        "\n",
        "    # Extract features for clustering\n",
        "    indices = [i for i, (path, label) in enumerate(train_dataset.samples) if label == train_dataset.class_to_idx[class_name]]\n",
        "    features = extract_features(train_dataset, indices)\n",
        "\n",
        "    # Perform K-Means clustering\n",
        "    n_clusters = 5  # You can change this\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(features)\n",
        "\n",
        "    # Count samples per cluster and find the smallest\n",
        "    cluster_counts = np.bincount(cluster_labels)\n",
        "    min_cluster = np.argmin(cluster_counts)\n",
        "\n",
        "    # Get paths of images in the minority cluster\n",
        "    minority_cluster_paths = [image_paths[i] for i in range(len(image_paths)) if cluster_labels[i] == min_cluster]\n",
        "\n",
        "    # Oversample minority cluster images first\n",
        "    extra_needed = TARGET_COUNT - len(images)\n",
        "    oversample_images = minority_cluster_paths * (extra_needed // len(minority_cluster_paths)) + random.choices(minority_cluster_paths, k=extra_needed % len(minority_cluster_paths))\n",
        "\n",
        "    for i, img_path in enumerate(oversample_images):\n",
        "        filename = os.path.basename(img_path)\n",
        "        new_filename = f\"oversampled_{i}_{filename}\"\n",
        "        shutil.copy(img_path, os.path.join(class_path, new_filename))\n",
        "\n",
        "# Apply adaptive oversampling to both classes separately\n",
        "for class_name in train_dataset.classes:\n",
        "    adaptive_oversampling(class_name)\n",
        "\n",
        "# Final check on dataset balance\n",
        "final_counts = {cls: len(os.listdir(os.path.join(COPIED_TRAIN_PATH, cls))) for cls in train_dataset.classes}\n",
        "print(f\"Balanced class counts: {final_counts}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8fNCf273X76",
        "outputId": "b5403bfb-8601-4533-8e6a-2b9d03a61e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Extracting Features: 100%|██████████| 13/13 [00:05<00:00,  2.49it/s]\n",
            "Extracting Features: 100%|██████████| 10/10 [00:05<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced class counts: {'cavity': 788, 'no_cavity': 788}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load Pre-trained Models with Correct Weights\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Remove final classification layers\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])  # ResNet outputs (batch, 512, 1, 1)\n",
        "inception.fc = nn.Identity()  # Remove Inception's classification layer\n",
        "\n",
        "# Move models to device\n",
        "resnet18.to(device).eval()\n",
        "inception.to(device).eval()\n",
        "\n",
        "# Define Image Transformations (InceptionNet requires 299x299 input size)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load Training and Test Data\n",
        "train_dataset = datasets.ImageFolder(root=\"dataset_cro/train/\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=\"dataset_cro/test/\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Function to extract features from both models\n",
        "def extract_features(loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(loader, desc=\"Extracting Features\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Extract features\n",
        "            resnet_features = resnet18(images).squeeze(-1).squeeze(-1)  # Shape: (batch, 512)\n",
        "            inception_features = inception(images)  # Shape: (batch, 2048)\n",
        "\n",
        "            # Flatten and concatenate features\n",
        "            resnet_features = resnet_features.cpu().numpy()\n",
        "            inception_features = inception_features.cpu().numpy()\n",
        "\n",
        "            combined_features = np.hstack((resnet_features, inception_features))\n",
        "\n",
        "            # Store features and labels\n",
        "            features.extend(combined_features)\n",
        "            labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Extract features for training and testing\n",
        "X_train, y_train = extract_features(train_loader)\n",
        "X_test, y_test = extract_features(test_loader)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Generate Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=train_dataset.classes)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jS6pHZT4_Wh",
        "outputId": "3cf980ee-6253-471e-a689-f82b1d952b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 50/50 [00:33<00:00,  1.48it/s]\n",
            "Extracting Features:  83%|████████▎ | 5/6 [00:02<00:00,  1.84it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
            "  warnings.warn(str(msg))\n",
            "Extracting Features: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      cavity       0.82      0.92      0.86        97\n",
            "   no_cavity       0.88      0.75      0.81        79\n",
            "\n",
            "    accuracy                           0.84       176\n",
            "   macro avg       0.85      0.83      0.84       176\n",
            "weighted avg       0.85      0.84      0.84       176\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Define dataset paths\n",
        "ORIGINAL_TRAIN_PATH = \"/content/drive/MyDrive/Cavity Dataset/train/\"\n",
        "ORIGINAL_TEST_PATH = \"/content/drive/MyDrive/Cavity Dataset/test/\"\n",
        "COPIED_TRAIN_PATH = \"dataset_col/train/\"\n",
        "COPIED_TEST_PATH = \"dataset_col/test/\"\n",
        "TARGET_COUNT = 400  # Target number of images per class\n",
        "\n",
        "# Function to check if an image is valid (not corrupted)\n",
        "def is_valid_image(img_path):\n",
        "    try:\n",
        "        img = cv2.imread(img_path)\n",
        "        return img is not None\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Function to copy dataset while removing corrupted images\n",
        "def copy_dataset(src, dest):\n",
        "    if os.path.exists(dest):\n",
        "        shutil.rmtree(dest)  # Remove existing copy\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    for class_folder in os.listdir(src):\n",
        "        src_class_path = os.path.join(src, class_folder)\n",
        "        dest_class_path = os.path.join(dest, class_folder)\n",
        "        os.makedirs(dest_class_path, exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(src_class_path):\n",
        "            img_path = os.path.join(src_class_path, filename)\n",
        "            if is_valid_image(img_path):\n",
        "                shutil.copy(img_path, dest_class_path)\n",
        "\n",
        "# Create a copy of the dataset, removing corrupted images\n",
        "copy_dataset(ORIGINAL_TRAIN_PATH, COPIED_TRAIN_PATH)\n",
        "copy_dataset(ORIGINAL_TEST_PATH, COPIED_TEST_PATH)\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load copied dataset\n",
        "train_dataset = ImageFolder(root=COPIED_TRAIN_PATH, transform=transform)\n",
        "\n",
        "# Load pre-trained ResNet50 as feature extractor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(dataset, indices):\n",
        "    dataloader = DataLoader(Subset(dataset, indices), batch_size=32, shuffle=False)\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in tqdm(dataloader, desc=\"Extracting Features\"):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            features.extend(outputs.squeeze().cpu().numpy())\n",
        "    return np.array(features)\n",
        "\n",
        "# Perform Adaptive Sampling via Clustering for both classes\n",
        "def adaptive_oversampling(class_name):\n",
        "    class_path = os.path.join(COPIED_TRAIN_PATH, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "    image_paths = [os.path.join(class_path, img) for img in images]\n",
        "\n",
        "    # Extract features for clustering\n",
        "    indices = [i for i, (path, label) in enumerate(train_dataset.samples) if label == train_dataset.class_to_idx[class_name]]\n",
        "    features = extract_features(train_dataset, indices)\n",
        "\n",
        "    # Perform K-Means clustering\n",
        "    n_clusters = 5  # You can change this\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(features)\n",
        "\n",
        "    # Count samples per cluster and find the smallest\n",
        "    cluster_counts = np.bincount(cluster_labels)\n",
        "    min_cluster = np.argmin(cluster_counts)\n",
        "\n",
        "    # Get paths of images in the minority cluster\n",
        "    minority_cluster_paths = [image_paths[i] for i in range(len(image_paths)) if cluster_labels[i] == min_cluster]\n",
        "\n",
        "    # Oversample minority cluster images first\n",
        "    extra_needed = TARGET_COUNT - len(images)\n",
        "    oversample_images = minority_cluster_paths * (extra_needed // len(minority_cluster_paths)) + random.choices(minority_cluster_paths, k=extra_needed % len(minority_cluster_paths))\n",
        "\n",
        "    for i, img_path in enumerate(oversample_images):\n",
        "        filename = os.path.basename(img_path)\n",
        "        new_filename = f\"oversampled_{i}_{filename}\"\n",
        "        shutil.copy(img_path, os.path.join(class_path, new_filename))\n",
        "\n",
        "# Apply adaptive oversampling to both classes separately\n",
        "for class_name in train_dataset.classes:\n",
        "    adaptive_oversampling(class_name)\n",
        "\n",
        "# Extract features and labels for SMOTE/ADASYN\n",
        "def get_features_and_labels(dataset):\n",
        "    indices = list(range(len(dataset)))\n",
        "    features = extract_features(dataset, indices)\n",
        "    labels = [label for _, label in dataset.samples]\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "features, labels = get_features_and_labels(train_dataset)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Apply SMOTE or ADASYN\n",
        "sampler = ADASYN(random_state=SEED)  # Change to ADASYN() if needed\n",
        "resampled_features, resampled_labels = sampler.fit_resample(features, encoded_labels)\n",
        "\n",
        "# Decode labels back to class names\n",
        "resampled_labels = label_encoder.inverse_transform(resampled_labels)\n",
        "\n",
        "# Function to generate synthetic images (Placeholder for actual reconstruction)\n",
        "def generate_synthetic_images(features, labels, dataset, target_path):\n",
        "    class_dirs = {cls: os.path.join(target_path, cls) for cls in dataset.classes}\n",
        "\n",
        "    for class_dir in class_dirs.values():\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for i, (feat, label) in enumerate(zip(features, labels)):\n",
        "        class_name = dataset.classes[label]\n",
        "        save_path = os.path.join(class_dirs[class_name], f\"synthetic_{i}.png\")\n",
        "\n",
        "        # Convert feature vector into an image (Placeholder: replace with proper inversion)\n",
        "        img = np.random.rand(224, 224, 3) * 255  # Dummy image, replace with actual reconstruction\n",
        "        img = Image.fromarray(img.astype(np.uint8))\n",
        "        img.save(save_path)\n",
        "\n",
        "# Generate synthetic images and save them\n",
        "generate_synthetic_images(resampled_features, resampled_labels, train_dataset, COPIED_TRAIN_PATH)\n",
        "\n",
        "# Final class counts\n",
        "final_counts = {cls: len(os.listdir(os.path.join(COPIED_TRAIN_PATH, cls))) for cls in train_dataset.classes}\n",
        "print(f\"Final balanced class counts: {final_counts}\")\n"
      ],
      "metadata": {
        "id": "4nCtv2QYHIkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a81c84-e5f3-4569-c553-945521ba7a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 178MB/s]\n",
            "Extracting Features: 100%|██████████| 13/13 [00:06<00:00,  2.10it/s]\n",
            "Extracting Features: 100%|██████████| 10/10 [00:05<00:00,  2.00it/s]\n",
            "Extracting Features: 100%|██████████| 23/23 [00:10<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final balanced class counts: {'cavity': 788, 'no_cavity': 778}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load Pre-trained Models with Correct Weights\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Remove final classification layers\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])  # ResNet outputs (batch, 512, 1, 1)\n",
        "inception.fc = nn.Identity()  # Remove Inception's classification layer\n",
        "\n",
        "# Move models to device\n",
        "resnet18.to(device).eval()\n",
        "inception.to(device).eval()\n",
        "\n",
        "# Define Image Transformations (InceptionNet requires 299x299 input size)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load Training and Test Data\n",
        "train_dataset = datasets.ImageFolder(root=\"dataset_col/train/\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=\"dataset_col/test/\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Function to extract features from both models\n",
        "def extract_features(loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(loader, desc=\"Extracting Features\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Extract features\n",
        "            resnet_features = resnet18(images).squeeze(-1).squeeze(-1)  # Shape: (batch, 512)\n",
        "            inception_features = inception(images)  # Shape: (batch, 2048)\n",
        "\n",
        "            # Flatten and concatenate features\n",
        "            resnet_features = resnet_features.cpu().numpy()\n",
        "            inception_features = inception_features.cpu().numpy()\n",
        "\n",
        "            combined_features = np.hstack((resnet_features, inception_features))\n",
        "\n",
        "            # Store features and labels\n",
        "            features.extend(combined_features)\n",
        "            labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Extract features for training and testing\n",
        "X_train, y_train = extract_features(train_loader)\n",
        "X_test, y_test = extract_features(test_loader)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Generate Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=train_dataset.classes)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgcI2Afp_ReG",
        "outputId": "55e81a8f-6355-4438-cd63-61b9fa1d93db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 175MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:00<00:00, 181MB/s] \n",
            "Extracting Features: 100%|██████████| 49/49 [00:22<00:00,  2.17it/s]\n",
            "Extracting Features:  83%|████████▎ | 5/6 [00:02<00:00,  1.54it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
            "  warnings.warn(str(msg))\n",
            "Extracting Features: 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      cavity       0.83      0.94      0.88        97\n",
            "   no_cavity       0.91      0.77      0.84        79\n",
            "\n",
            "    accuracy                           0.86       176\n",
            "   macro avg       0.87      0.86      0.86       176\n",
            "weighted avg       0.87      0.86      0.86       176\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Define dataset paths\n",
        "ORIGINAL_TRAIN_PATH = \"/content/drive/MyDrive/Cavity Dataset/train/\"\n",
        "ORIGINAL_TEST_PATH = \"/content/drive/MyDrive/Cavity Dataset/test/\"\n",
        "COPIED_TRAIN_PATH = \"dataset_cv/train/\"\n",
        "COPIED_TEST_PATH = \"dataset_cv/test/\"\n",
        "TARGET_COUNT = 788  # Target number of images per class\n",
        "\n",
        "# Function to check if an image is valid (not corrupted)\n",
        "def is_valid_image(img_path):\n",
        "    try:\n",
        "        img = cv2.imread(img_path)\n",
        "        return img is not None\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Function to copy dataset while removing corrupted images\n",
        "def copy_dataset(src, dest):\n",
        "    if os.path.exists(dest):\n",
        "        shutil.rmtree(dest)  # Remove existing copy\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    for class_folder in os.listdir(src):\n",
        "        src_class_path = os.path.join(src, class_folder)\n",
        "        dest_class_path = os.path.join(dest, class_folder)\n",
        "        os.makedirs(dest_class_path, exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(src_class_path):\n",
        "            img_path = os.path.join(src_class_path, filename)\n",
        "            if is_valid_image(img_path):\n",
        "                shutil.copy(img_path, dest_class_path)\n",
        "\n",
        "# Create a copy of the dataset, removing corrupted images\n",
        "copy_dataset(ORIGINAL_TRAIN_PATH, COPIED_TRAIN_PATH)\n",
        "copy_dataset(ORIGINAL_TEST_PATH, COPIED_TEST_PATH)\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load copied dataset\n",
        "train_dataset = ImageFolder(root=COPIED_TRAIN_PATH, transform=transform)\n",
        "\n",
        "# Simple Oversampling Function\n",
        "def simple_oversampling(class_name):\n",
        "    class_path = os.path.join(COPIED_TRAIN_PATH, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "\n",
        "    if len(images) >= TARGET_COUNT:\n",
        "        return  # No oversampling needed\n",
        "\n",
        "    extra_needed = TARGET_COUNT - len(images)\n",
        "    oversample_images = random.choices(images, k=extra_needed)\n",
        "\n",
        "    for i, img_name in enumerate(oversample_images):\n",
        "        src_path = os.path.join(class_path, img_name)\n",
        "        new_filename = f\"oversampled_{i}_{img_name}\"\n",
        "        dst_path = os.path.join(class_path, new_filename)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Apply simple oversampling to both classes\n",
        "for class_name in train_dataset.classes:\n",
        "    simple_oversampling(class_name)\n",
        "\n",
        "# Final class counts\n",
        "final_counts = {cls: len(os.listdir(os.path.join(COPIED_TRAIN_PATH, cls))) for cls in train_dataset.classes}\n",
        "print(f\"Final balanced class counts: {final_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrWuJGni_6bM",
        "outputId": "d8f80706-6186-4d42-f342-dc06ded93246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final balanced class counts: {'cavity': 788, 'no_cavity': 788}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load Pre-trained Models with Correct Weights\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Remove final classification layers\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])  # ResNet outputs (batch, 512, 1, 1)\n",
        "inception.fc = nn.Identity()  # Remove Inception's classification layer\n",
        "\n",
        "# Move models to device\n",
        "resnet18.to(device).eval()\n",
        "inception.to(device).eval()\n",
        "\n",
        "# Define Image Transformations (InceptionNet requires 299x299 input size)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load Training and Test Data\n",
        "train_dataset = datasets.ImageFolder(root=\"dataset_cv/train/\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=\"dataset_cv/test/\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Function to extract features from both models\n",
        "def extract_features(loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(loader, desc=\"Extracting Features\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Extract features\n",
        "            resnet_features = resnet18(images).squeeze(-1).squeeze(-1)  # Shape: (batch, 512)\n",
        "            inception_features = inception(images)  # Shape: (batch, 2048)\n",
        "\n",
        "            # Flatten and concatenate features\n",
        "            resnet_features = resnet_features.cpu().numpy()\n",
        "            inception_features = inception_features.cpu().numpy()\n",
        "\n",
        "            combined_features = np.hstack((resnet_features, inception_features))\n",
        "\n",
        "            # Store features and labels\n",
        "            features.extend(combined_features)\n",
        "            labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Extract features for training and testing\n",
        "X_train, y_train = extract_features(train_loader)\n",
        "X_test, y_test = extract_features(test_loader)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Generate Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=train_dataset.classes)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zHcJA_GAEtz",
        "outputId": "80fba3a6-bb42-4e2b-f9b2-9fefec4c3e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 50/50 [00:27<00:00,  1.79it/s]\n",
            "Extracting Features:  83%|████████▎ | 5/6 [00:02<00:00,  1.76it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
            "  warnings.warn(str(msg))\n",
            "Extracting Features: 100%|██████████| 6/6 [00:03<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      cavity       0.84      0.92      0.88        97\n",
            "   no_cavity       0.89      0.78      0.83        79\n",
            "\n",
            "    accuracy                           0.86       176\n",
            "   macro avg       0.86      0.85      0.85       176\n",
            "weighted avg       0.86      0.86      0.86       176\n",
            "\n"
          ]
        }
      ]
    }
  ]
}